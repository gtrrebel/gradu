\chapter{Introduction}

\section{Foreword}

This master's thesis delves into the theory of matrix monotone functions. Matrix monotonicity is generalization of standard monotonicity f real functions: now we are just having functions mapping matrices to matrices. Formally, $f$ is \textit{matrix monotone} if for any two matrices $A$ and $B$ such that
\begin{align}
	A \leq B
\end{align}
we should also have
\begin{align}
	f(A) \leq f(B).
\end{align}

This kind of function might be more properly called \textit{matrix increasing} but we will mostly stick to the monotonicity for couple of reasons:
\begin{itemize}
	\item For some reason, that is what people have been doing in the field.
	\item It doesn't make much difference whether we talk about increasing or decreasing functions, so we might just ignore the latter but try to symmetrize our thinking by choice of words.
	\item Somehow I can't satisfactorily fill the following table:
	\begin{center}
	\begin{tabular}{| c | c |}
		\hline
		monotonic & monotonicity \\
		\hline
		increasing & ? \\
		\hline
	\end{tabular}
	\end{center}
	How very inconvenient.
\end{itemize}

Of course, it's not really obvious how one should make any sense of these ``definitions''. There two things to understand.
\begin{itemize}
	\item How should matrices be ordered?
	\item How should functions act on matrices?
\end{itemize}
Both of these questions can be (of course) answered in many ways, but for both of them, there is very natural answer. In both cases we can get something more general: instead of comparing matrices we can compare linear maps, and we can apply function to linear mapping.

Just to give a short glimpse of how these things might be defined, we should first fix our ground field (for matrices): let's say it's $\R$, at least for now.

For matrix ordering we should first understand which matrices are \textit{positive}, which here, a bit confusingly maybe, means ``at least zero". We can't have everything: For instance, it's not very hard to see that it is not possible to give notion of positivity on space of all real $n \times n$ matrices which respects similarity. If we give our space inner product, and restrict to a nice subspace of linear maps, called Hermitian maps, we can have a notion of positivity which respects unitary similarity.

Matrix functions, i.e. ``how to apply function to matrix" is bit simpler to explain. Instead of considering arbitrary maps the idea is to take a real function ($f : \R \to \R$, say) and intepret it as function $f : \R^{n \times n} \to \R^{n \times n}$, \textit{matrix function}. Polynomials extend rather naturally, and similarly analytic functions, or at least entire. Now, a perverse definition for matrix function for continuous functions would be some kind of a limit when function is uniformly approximated by polynomials (using Weierstrass approximation theorem). This works for Hermitian matrices, but one can do better: apply the function to the eigenvalues of the mapping to get another linear map.

Lastly, one might wonder why should one be interested in the whole business of matrix monotone functions? It's all about point of view.\footnote{And there are some real applications too $\ldots$.} Let's consider a very simple inequality:

For any real numbers $0 < x \leq y$ we have
\[
	y^{-1} \leq x^{-1}.
\]
Of course, this is quite close to the axioms of the real numbers, but there's a rather fruitful interpretation. The function $(x \mapsto \frac{1}{x})$ is decreasing.

Now there's this matrix version of the previous inequality:

For any two matrices $0 < A \leq B$ we have
\[
	B^{-1} \leq A^{-1}.
\]
This is already not trivial, and with previous interpretation in mind, could this be interpreted as the functions $(x \mapsto \frac{1}{x})$ could be \textit{matrix decreasing}? And is this just a special case of something bigger? Yes, and that's exactly what this thesis is about.

\section{Goals}

Main goal of this thesis is to understand two basic results (theorems TODO and TODO) on matrix monotone functions, which read roughly as follows.

\begin{lause}
	If a function is matrix monotone for $n \times n$ matrices, then it is $C^{2 n - 3}$.
\end{lause}

\begin{lause}
	If a function is matrix monotone for $n \times n$ matrices for every $n$, then it is analytic and extends analytically to upper half-plane.
\end{lause}

Both of these result can be turned to ``if and only" -characterizations, but let us ignore the technicalities for know. The giveaway is that matrix monotone functions are quite regular.

Why is that? Where does regularity come from? The only thing we know about matrix monotone functions is essentially some positivity condition (difference of matrices being positive). The moral goal of the thesis is to explain that it is exactly the positivity that leads to regularity.

\begin{phil}
	Positiveness leads to regularity.
\end{phil}

\section{Positive objects}

One of the main themes in this thesis is the notion of \textit{closed salient cone}. They work like sets of positive numbers.

\begin{maar}
	Let $V$ be a topological vector space over $\R$ or $\C$ and $C \subset V$. Then $C$ is \textit{closed salient cone} of $V$ if
	\begin{enumerate}[(i)]
		\item For every $v \in C$ and $\alpha > 0$ we have $\alpha v \in C$.
		\item For every $v, w, \in C$ we have $v + w \in C$.
		\item $0 \in C$.
		\item If both $v \in C$ and $-v \in C$, then $v = 0$.
		\item $C$ is closed.
	\end{enumerate}
\end{maar}

Subsets of vector spaces satisfying the first one, two, three and four properties are called \textit{cones}, \textit{convex cones}, \textit{pointed cones} and \textit{salient cones}, respectively. To shorten the terminology we call closed salient cones \textbf{\textit{proper cones}}, as is also somewhat customary.

(Pictures of every possibility)

As mentioned, proper cones are an attempt to generalize the set of non-negative real numbers to a vector space. The first four conditions are pretty much direct translations of the axioms of non-negative numbers to vector spaces. The closedness condition is more of a convenience. Every proper cone gives rise to partial order on the vector space. This makes the vector space (not surprisingly) \textit{ordered topological vector space}.

\begin{maar}
	Let $V$ be a topological vector space over $\R$ or $\C$ and $\leq \in V^{2}$ a relation on $V$. Then $(V, \leq)$ is \textit{ordered topological vector space} if
	\begin{enumerate}[(i)]
		\item $\leq$ is partial order in $V$, that is
		\begin{enumerate}
			\item $v \leq v$ for any $v \in V$.
			\item If $v, w, u$ such that $v \leq w$ and $w \leq u$, then also $v \leq u$.
			\item If for some $v, w \in V$ we have both $v \leq w$ and $w \leq u$, then $v = w$.
		\end{enumerate}
		\item If $v, w \in V$ are such that $v \leq w$, then also $v + u \leq w + u$ for any $u \in V$.
		\item If $v, w \in V$ are such that $v \leq w$, then for any $\alpha \in [0, \infty)$ also $\alpha v \leq \alpha w$.
		\item The set $\{v \in V | 0 \leq v\}$ is closed.
	\end{enumerate}
\end{maar}

Of course, one should always hope the order $\leq$ to be total, but this is usually wishful thinking, at least if one wants $\leq$ to be canonical in some way.

\begin{prop}
	For any proper cone $C$ of topological vector space $V$ the relation $\leq_{C}$ defined by
	\begin{align*}
		v \leq_{C} w \Leftrightarrow w - v \in C
	\end{align*}
	makes $(V, \leq_{C})$ ordered topological vector space.
\end{prop}
\begin{proof}
	Easy to check.
\end{proof}

Conversely, for every ordered topological vector space $(V, \leq)$ the set $\{v \in V | 0 \leq v\}$ is a proper cone (which induces $\leq$). Elements of the set $\{v \in V | 0 \leq v\}$ are called the \textit{positive elements} of $(V, \leq)$, or simply \textit{positive}. This terminology is rather unfortunate: if $V = \R$, then the positive elements in $(\R, \leq)$ coincide with the non-negative reals (and not the positive ones). The problem is that with non-total orders the term non-negative should mean something totally different. While potentially confusing, we stick with term positive because of the following reasons:
\begin{enumerate}
	\item It's short.
\end{enumerate}

\section{Structure}

The next four chapters are devoted to the four main proper cones of this thesis.

\begin{itemize}
	\item \textbf{Positive maps} (i.e. positive semidefinite maps). These are the main objects of interest and they are used to define the matrix monotone functions, as illustrated in the introduction. As a comprehensive account of these creatures is far beyond the scope of this thesis, only certain aspects, most relevant to the main topic, are discussed. Should the reader lack familiarity with positive maps, the author farmly recommends TODO as a welcome to the topic.

	Nevertheless, chapter should be self-contained given the background topics (in the next section).

	\item \textbf{k-tone functions}. $k$-tone functions are essentially functions with non-negative $k$'th derivative. Many of the regularity phenomena discussed in this thesis can be understood through the properties of these functions.

	\item \textbf{Pick functions}. Pick functions are analytic functions on upper half-plane with non-negative imaginary part. It turns out that these functions are intimately linked to matrix monotone functions.

	\item \textbf{Matrix monotone functions}. These are the main objects of the study and all the theory build so far is finally connected.
\end{itemize}

To be entirely honest, only the first of the four proper cones is really a proper cone (three others fail the fourth condition), but the shortcomings of the others are so minor and canonical that we still call them proper.

The last chapter discusses TODO.

\section{Plan of attack}

This master's thesis is a comprehensive review of the rich theory of matrix monotone functions.

Master's thesis is to be structured roughly as follows.

\begin{enumerate}
	\item Introduction
		\begin{itemize}
			\item Introduction to the problem, motivation
			\item Brief definition of the matrix monotonicity and convexity
			\item Past and present (Is this the right place)
				\begin{itemize}
					\item Loewner's original work, Loewner-Heinz -inequality
					\item Students: Dobsch' and Krauss'
					\item Subsequent simplifications and further results: Bendat-Sherman, Wigner-Neumann, Koranyi, etc.
					\item Donoghue's work
					\item Later proofs: Krein-Milman, general spectral theorem, interpolation spaces, short proofs etc.
					\item Development of the convex case
					\item Recent simplifications, integral representations
					\item Operator inequalities
					\item Multivariate case, other variants
					\item Further open problems?
				\end{itemize}
			\item Scope of the thesis
		\end{itemize}
	\item Positive matrices
		\begin{itemize}
			\item Motivation via restriction, basics
			\item Spectral theorem
			\item Congruence
			\item Characterizations
			\item Applications
			\item Spectrum
		\end{itemize}
	\item Divided differences
		\begin{itemize}
			\item Definition (what kind of?)
			\item Mean value theorem
			\item Smoothness
			\item k-tone functions on $\R$
			\item Cauchy's integral formula
			\item Regularizations
		\end{itemize}
	\item Matrix functions
		\begin{itemize}
			\item Several definitions: spectral and cauchy
			\item Smoothness of matrix functions
		\end{itemize}
	\item Pick functions
		\begin{itemize}
			\item Basic definitions and properties
			\item Pick matrices/ determinants
			\item Compactness
			\item Pick-Nevanlinna interpolation theorem
			\item Pick-Nevanlinna representations theorem
		\end{itemize}
	\item Monotonic and convex matrix functions
		\begin{itemize}
			\item Basics
				\begin{itemize}
					\item Basic definitions and properties (cone structure, pointwise limits, compositions etc.)
					\item Classes $P_{n}, K_{n}$ and their properties
					\item $-1/x$
					\item One directions of Loewner's theorem
					\item Examples and non-examples
				\end{itemize}
			\item Pick matrices/determinants vs matrix monotone and convex functions
				\begin{itemize}
					\item Proofs for (sufficiently) smooth functions
				\end{itemize}
			\item Smoothness properties
				\begin{itemize}
					\item Ideas, simple cases
					\item General case by induction and regularizations
				\end{itemize}
			\item Global characterizations
				\begin{itemize}
					\item Putting everything together: we get original characterization of Loewner and determinant characterization
				\end{itemize}
		\end{itemize}
	\item Local characterizations
		\begin{itemize}
			\item Dobsch (Hankel) matrix: basic properties, easy direction (original and new proof)
			\item Integral representations
				\begin{itemize}
					\item Introducing the general weight functions for monotonicity and convexity (and beyond?)
					\item Non-negativity of the weights
					\item Proof of integral representations
				\end{itemize}
			\item Proof of local characterizations
		\end{itemize}
	\item Structure of the classes $P_{n}$ and $K_{n}$, interpolating properties (?)
		\begin{itemize}
			\item Strict inclusions, strict smoothness conditions
			\item Strictly increasing functions
			\item Extreme values
			\item Interpolating properties
		\end{itemize}
	\item Loewner's theorem
		\begin{itemize}
			\item Preliminary discussion, relation to operator monotone functions
			\item Loewner's original proof
			\item Pick-Nevanlinna proof
			\item Bendat-Sherman proof
			\item Krein-Milman proof
			\item Koranyi proof
			\item Discussion of the proofs
			\item Convex case
		\end{itemize}
	\item Alternative characterizations (?)
		\begin{itemize}
			\item Some discussion, maybe proofs
		\end{itemize}
	\item Bounded variations (?)
		\begin{itemize}
			\item Dobsch' definition, basic properties
			\item Decomposition, Dobsch' theorems
		\end{itemize}
\end{enumerate}

\section{How to rewrite this thesis}

\begin{enumerate}
	\item Positive maps: lose all the fat.
	\item Divided differences: concentrate on important things, namely relationship between smoothness and $k$-tone functions.
	\item Keep it relatively short, as it is (?)
	\item Pick functions: is this the place for these. Start with Schwarz lemma as an rigidity example. Then express Schwarz lemma with contour integrals: generalize, proof by tricks. Notion of Pick points, and finally Pick-Nevanlinna interpolation theorem, some form of it.
\end{enumerate}

\section{Some random ideas}
\begin{enumerate}
	\item TODO: fix Boor in the references
	\item It's easy to see that [Something]. Actually, it's so so easy that we have no excuse for not doing it.
	\item When is matrix of the form $f(a_{i} + a_{j})$ positive: $f$ is completely monotone (?).
	\item Polynomial regression...
	\item TODO: Maximum of two matrices (at least as big), $(a + b)/2 + abs(a - b)/2$
	\item If $\langle A x, y \rangle = 0$ implies $\langle x, A y \rangle = 0$, then $A$ is constant times hermitian.
	\item Angularity preserving functions
	\item If subspace of linear maps are diagonalizable with real eigenvalues, is there a inner product such that subspace consists of only Hermitian maps
	\item One should be alarmed should one see a positive cone.
	\item Make DAG (hopefully) of logical structure of the thesis, colour-coded (with respect to the topic, maybe). Theorem numbers, maybe named theorems with names. To the introduction.
	\item Cut the bullshit
\end{enumerate}

\section{Main TODO -list}
\subsection{Missing proofs}
\begin{enumerate}
	\item Eigenvalues of $AB$ when $A$ and $B$ are positive (?)
	\item Symmetric product fail (?)
	\item Hindmarsh theorem
	\item non-smooth Dobsch char.
	\item classes are different
	\item matrix $k$-tone (please expand)
\end{enumerate}

\subsection{Sections to write}
\begin{enumerate}
	\item \textcolor{red}{Integral representations}
	\item \textcolor{red}{All ``Notes and references" sections}
	\item More on convex and $k$-tone matrix functions
\end{enumerate}

\subsection{Figures to make}
\begin{enumerate}
	\item Proof of spectral theorem
	\item Compression
	\item Pictures of Peano kernels
	\item $k$-tone functions: visual definition
	\item $k$-tone functions are smooth
	\item Pick functions and measures
	\item Mean value theorem
	\item Pick extension lemma
	\item Eigenvalue inequalities: projections and compressions
	\item Concrete Pick function extension procedure
	\item Change of eigenvalues of $A + t B$
	\item Disc lemma
	\item Cones in the introduction
\end{enumerate}


