\chapter{Matrix functions}

\section{Functional calculus}

\begin{maar}
	For any $-\infty \leq a < b \leq \infty$ $f : (a, b) \to \R$ the associated matrix function on $V$ is the map $f_{V} : \H_{(a, b)}(V) \to \H(V)$ given by
	\[
		f_{V}\left(A\right) = \sum_{\lambda \in \spec(A)} f(\lambda) P_{E_{\lambda}}
	\]
	if $A = \sum_{\lambda \in \spec(A)} \lambda P_{E_{\lambda}}$.
\end{maar}
Hence to calculate the matrix function we just apply the function to the eigenvalues of the map and leave the eigenspaces as they are. Note as the spectral representation is unique this definition makes sense.

We have already discussed four types of matrix functions: inverse, polynomials, square root and absolute value. All these notion coincide with the general notion of matrix function for real maps, as notion in (\ref{polynomial_matrix_function}) and TODO.

Matrix functions enjoy many natural and useful properties.

\begin{prop}\label{basic_matrix}
	Let $f : (a,b) \to \R$ and $A \in \H_{(a, b)}$
	\begin{enumerate}
		\item If $f[(a, b)] \subset (c, d)$ then $f_{V}(A) \in \H_{(c, d)}$.
		\item If also $g : (a, b) \to \R$ then $(f + g)_{V} = f_{V} + g_{V}$ and $(fg)_{V} = f_{V}g_{V}$.
		\item $f_{V_{1} \oplus V_{2}} = f_{V_{1}} \oplus f_{V_{2}}$.
		\item If $g : (a, b) \to \R$ and $f$ and $g$ agree on spectrum of $A$, then $f(A) = g(A)$.
		\item If $f[(a, b)] \subset (c, d)$ and $g : (c, d) \to \R$ then $(g \circ f)_{V} = g_{V} \circ f_{V}$.
		\item If $f_{n} : (a, b) \to \R$ converge pointwise to $f$, then the same holds true for $(f_{n})_{V}$'s.
	\end{enumerate}
\end{prop}

These properties make it clear that such definition is natural. We will drop the subscript $V$ and identify $f$ with its matrix function $f_{V}$ if $V$ is clear from context.

\section{Holomorphic functional calculus}

If $f$ is entire, there's another way to appoach matrix functions. As $f$ can be written as
\[
	f(z) = \sum_{n = 0}^{\infty} a_{n} z^{n},
\]
power series convergent whole any $z \in \C$, we should have
\[
	f_{V}(A) = \sum_{n = 0}^{\infty} a_{n} A^{n}.
\]
This matrix power series indeed converges as $\|A^{n}\| \leq \|A\|^{n}$. Also, this definition coincides with the spectral one. Indeed, if one writes $f_{n} : z \mapsto  \sum_{k = 0}^{n} a_{n} z^{n}$, then we have, by definition,
\[
	\sum_{n = 0}^{\infty}a_{n} A^{n} = \lim_{n \to \infty} \left[(f_{n})_{V}(A) \right] = f_{V}(A),
\]
by point (6) of proposition (\ref{basic_matrix}).

Note however that the power series definition makes perfect sense even if $a_{n} \notin \R$ and even better, $A$ need not be real.

If $f$ is not entire, the power series might not converge every $A \in \H_{(a, b)}(V)$. Instead, we can more generally use Cauchy's integral formula for matrix functions.
\[
	f_{V}(A) = \int_{\gamma} (z I - A)^{-1} f(z) dz,
\]
where $\gamma$ is simple closed curve enclosing the spectrum of $A$. This formula is immediate when viewed in a eigenbasis of $A$. Again, this formula makes perfect sense even for non-real $A$, given that spectrum of $A$ lies in the domain of $f$.

\section{Derivative of a matrix function}

If $f$ is analytic, for suitable $\gamma$ we have
\begin{align*}
	f(B) - f(A) &= \int_{\gamma} (z I - B)^{-1} f(z) dz - \int_{\gamma} (z I - A)^{-1} f(z) dz \\
	&= \int_{\gamma} (z I - B)^{-1} (B - A) (z I - A)^{-1} f(z) dz.
\end{align*}
Writing $B = A + t H$, and letting $t \to 0$ we get
\begin{align*}
	\lim_{t \to 0} \frac{f(A + tH) - f(A)}{t} &= \lim_{t \to 0}\int_{\gamma} (z I - A - t H)^{-1} H (z I - A)^{-1} f(z) dz \\
	&= \int_{\gamma} (z I - A)^{-1} H (z I - A)^{-1} f(z) dz.
\end{align*}

Derivative of $f$ at $A$ is hence the linear map
\begin{align*}
	H \mapsto \int_{\gamma} (z I - A)^{-1} H (z I - A)^{-1} f(z) dz.
\end{align*}

If we write everything in the eigenbasis of $A$, $A = (\lambda_{i} \delta_{i, j})_{1 \leq i, j \leq n}$ and $H = (H_{i, j})_{1 \leq i,j \leq n}$, we have
\begin{align*}
	\int_{\gamma} (z I - A)^{-1} H (z I - A)^{-1} f(z) dz &= \left(H_{i, j} \int_{\gamma} (z - \lambda_{i})^{-1} (z - \lambda_{j})^{-1} f(z) dz \right)_{1 \leq i, j \leq n} \\
	&= \left(H_{i, j} [\lambda_{i}, \lambda_{j}]_{f} \right)_{1 \leq i, j \leq n} \\
	&= H \circ \left([\lambda_{i}, \lambda_{j}]_{f} \right)_{1 \leq i, j \leq n}.
\end{align*}
Here $\circ$ denotes the Hadamard product of matrices, given by $(A \circ B)_{i, j} = A_{i, j} \circ B_{i, j}$.

This formula holds even if $f$ is not analytic, namely as long as $f \in \C^{1}(a, b)$. Indeed, by polynomial interpolation it is sufficient to prove the following lemma.
\begin{lem}
	If $f \in C^{1}(a, b)$, $A \in \H_{(a, b)}$ such that $f(\lambda_{i}) = 0 = f'(\lambda_{i})$ for $1 \leq i \leq n$, then
	\[
		\|f(A + H)\| = o(\|H\|).
	\]
\end{lem}
\begin{proof}
	TODO
\end{proof}

\begin{comment}

TODO: Start with polynomials.

If $f$ is entire with $f(z) = \sum_{n = 0}^{\infty} a_{n} z^{n}$ we have
\begin{align*}
	f(A + B) &= a_{0} I \\
			&+ a_{1} (A + B) \\
			&+ a_{2} (A^2 + AB + BA + B^2) \\
			&+ a_{3} (A^3 + A^2 B + ABA + AB^2 + BA^2 + BAB + B^2A + B^3) \\
			&+ \ldots
\end{align*}
Hence we have
\begin{align*}
	\lim_{t \to 0} \frac{f(A + tB) - f(A)}{t} &= a_{1} B \\
			&+ a_{2} (AB + BA) \\
			&+ a_{3} (B A^2 + ABA + A^2 B) \\
			&+ a_{4} (B A^{3} + ABA^2 + A^2BA + A^3 B) \\
			&+ \ldots \\
			&= \sum_{n = 1}^{\infty} a_{n} \sum_{0 \leq k \leq n - 1} A^{k} B A^{n - 1 - k}.
\end{align*}

\end{comment}

\section{Slick proof}

We give slick proof for the fact $f \in C^{\omega}(a, b) \cap P_{\infty}(a, b)$ then the Pick matrices are positive. Pick matrices being positive is equavalent to
\[
	\frac{1}{2 \pi i}\int_{\gamma} f(z) \left|\sum_{1 \leq i \leq n}\frac{c_{i}}{z - z_{i}} \right| d z \geq 0
\]
for any $c_{i} \in \C$ and $z_{i} \in \Hp$ such that $\gamma$ encloses $z_{i}$'s. Now what we know is that this holds if $z_{i}$'s are real and we can let some points coincide. But then we consider $g_{k}(z) = \frac{1}{z^{k}}\sum_{i = 1}^{n} c_{i} \frac{z^{k} - z_{i}^{k}}{z - z_{i}}$, this converges pointwise to what we want, at least for suitable $z_{i}$'s, and it is of the right form, so we have the claim, essentially. To elaborate a little, we integrate
\[
	\frac{1}{2 \pi i}\int_{\gamma} f(z) |g_{k}(z)|^{2} dz.
\]
As $k \to \infty$, this approaches what we want. Absolute values might a bit off, but something like this.


TODO:
\begin{itemize}
	\item Basic definition
	\item Equivalent definitions
	\item Continuity properties
	\item Examples
	\item Calculating with matrix functions
	\item Smoothness properties, derivative formulas, Hadamard product
	\item Cauchy's integral formula
	\item Jordan block formula
\end{itemize}
